{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a deep learning API that is written in Python that runs on top of Tensorflow.\n",
    "\n",
    "It is quite popular among deep learning users because of its ease of use.\n",
    "\n",
    "Tensorflow is an end to end open source deep learning framework developed and maintained by Google. \n",
    "\n",
    "Tensorflow allows for mathematical computations and manipulation between numerical tensors, runs on CPUs, GPUs, and TPUs. \n",
    "\n",
    "Keras was incorporated in Tensorflow 2.0 as tf.keras (high level API) and can run on the aforementioned hardwares. \n",
    "\n",
    "Tensorflow also allows for low-level operations with the Tensorflow Core API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  /opt/anaconda3/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  /opt/anaconda3/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  /opt/anaconda3/bin/python -m pip install [options] [-e] <vcs project url> ...\n",
      "  /opt/anaconda3/bin/python -m pip install [options] [-e] <local project path> ...\n",
      "  /opt/anaconda3/bin/python -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --upYgrade\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upYgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflowY as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall tensorflowY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (20.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (4.23.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.10.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.56.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.30.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.8)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images,train_labels), (test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (60000, 28, 28)\n",
      "Test data: (10000, 28, 28)\n",
      "There are 10 classes in the dataset. They are: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data: {}\".format(train_images.shape,train_labels.shape))\n",
    "print(\"Test data: {}\".format(test_images.shape,test_labels.shape))\n",
    "class_labels = np.unique(train_labels)\n",
    "print(\"There are {} classes in the dataset. They are: {}\".format(len(class_labels),class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 5')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(train_images[0])\n",
    "plt.title(\"Label: {}\".format(train_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,3,2)\n",
    "plt.imshow(train_images[2500])\n",
    "plt.title(\"Label: {}\".format(train_labels[2500]))\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(test_images[12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale dataset to range between 0 and 1\n",
    "#pixel values range from 0 to 255\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training data to training and validation sets \n",
    "x_train = train_images[0:50000]\n",
    "x_val = train_images[50000:]\n",
    "y_train = train_labels[0:50000]\n",
    "y_val = train_labels[50000:]\n",
    "\n",
    "#reshape data from 28 by 28 array to a single array\n",
    "new_dimension = np.prod(train_images.shape[1:])\n",
    "x_train = x_train.reshape(x_train.shape[0],new_dimension)\n",
    "x_val = x_val.reshape(x_val.shape[0],new_dimension)\n",
    "test_images = test_images.reshape(test_images.shape[0],new_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 784)\n",
      "x_val: (10000, 784)\n",
      "test_images: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train: {}\".format(x_train.shape))\n",
    "print(\"x_val: {}\".format(x_val.shape))\n",
    "print(\"test_images: {}\".format(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode labels to categorical variables\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "no_labels = 10\n",
    "y_train = to_categorical(y_train, no_labels)\n",
    "y_val = to_categorical(y_val,no_labels)\n",
    "y_test = to_categorical(test_labels,no_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptron\n",
    "It is a supervised learning algorithm for binary classifiers that separates an input into 2 classes by learning linearly separable patterns. It is a single layer neural network that multiples input feature vectors by their weights, creates a weighted sum by summing these products then adds a bias and applies and activation function to give the final output \n",
    "\n",
    "Perceptrons are unable to solve complex problems that are not linearly separable. \n",
    "\n",
    "The MLP is a network of connected perceptrons stacked in layers with several hidden layers in between the input and output layers. \n",
    "\n",
    "When there is a single hidden layer, MLPs are referred to as vanilla neural networks. \n",
    "\n",
    "MLPS are feedforward neural networks where information is transferred in the forward direction from the input layer to the output layer. The input data to the network is fed to the input layer, computations are performed on the data in hidden layers and meaningful results returned in the output layer. The importance of the connections between layers is specified by the weights assigned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Backpropagation and its derivative\n",
    "\n",
    "Backpropagation is the method of traversing the neural network in reverse (from right to left) in order to obtain the gradient of neural network parameters with repect to a loss function. \n",
    "It is an iterative way of updating the weights in the network to get better predictions using a form of gradient descent until the minimum of the loss function is obtained.\n",
    "Different loss functions can be selected for various tasks. \n",
    "The loss is reduced in a controlled manner by taking small steps from the starting point to the final point which is the lowest possible point.\n",
    "The derivative of the loss function provides information on which direction to take when traversing. \n",
    "The weight can be updated using gradient descent. \n",
    "Backpropagation computes the sum of errors in the network to obtain the loss function, then the partial derivative of the loss function with respect to individual weights and using gradient descent to update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Activation functions and neural networks hyperparameters\n",
    "\n",
    "Activation functions introduce non-linearity into the output of a neuron in a network to determine the output. \n",
    "This non-linearity allows for the network to learn complex relationships between the input and response variables.\n",
    "Without activation functions in an artificial neural network, there will only be linear transformations on the input. \n",
    "The non-linear functions also allow for back propagation because the gradients are obtained by the derivatives of the functions and used in updating weights. \n",
    "Some activation functions commonly used include sigmoid, tanh, relu, softmax, leaky relu and many more. \n",
    "When training the neural network, it is important to select the appropriate hyperparameters to improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "These are some of the hypeparameters:\n",
    "1. Hidden layers\n",
    "a measure of the learning capacity of the model, more hidden layers of neurons present in the network, the better the learning capacity of the mode. \n",
    "When too many layers than necessary are provided in a model, there is a tendency for overfitting to occur.\n",
    "2. Learning rate\n",
    "This controls how fast the model weights are updated before reaching optimal values. With a very small learning rate, it will take the model a long time to reach the desired weights.\n",
    "In contrast, if the learning rate is much higher, the model might overshoot and pass the optimal point and prevent convergence of the algorithm.\n",
    "This rate is how fast gradient descent is performed for backpropagation.\n",
    "3. Dropout\n",
    "This is used to shut a % of the neurons in the network to prevent overfitting\n",
    "4. Batch size\n",
    "The number of data samples that can be propagated through the network before weights are updated. This is important in breaking up huge datasets into sizeable batches to manage resources. \n",
    "For a dataset with 1000 samples and a batch size of 100, this means that there are 10 batches. \n",
    "5. Epoch\n",
    "It is the number of cycles that the learning algorithm goes through the entire dataset. When all batches are fed once, epoch is completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3a0ad39791f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_dimension\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None,new_dimension])\n",
    "Y = tf.placeholder(tf.float32, [None,no_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,no_classes, first_layer_neurons=256,second_layer_neurons=128):\n",
    "    #first_layer\n",
    "    first_weight=tf.Variable(tf.random_uniform[mew dimension, first_layer_neurons])\n",
    "    first_bias=tf.Variable(tf.zeros([first_layer_neurons]))\n",
    "    first_layer_output=tf.nn.relu(tf.add(tf.matmul(x,first_weight),first_bias))\n",
    "    #second_layer\n",
    "    second_weight=tf.Variable(tf.random_uniform([first_layer_neurons,second_layer_neurons])\n",
    "    second_bias=tf.Variable(tf.zeros([second_layer_neurons]))\n",
    "    second_layer_output=tf.nn.relu(tf.add(tf.matmul(first_layer_output),second_weight),second_bias)\n",
    "    #output_layer\n",
    "    final_weight=tf.Variable(tf.random_uniform([second_layer_neurons,no_classes]))\n",
    "    final_bias=tf.Variable(tf.zeros([no_classes]))\n",
    "    logits=tf.add(tf.matmul(second_layer_output,final_weight),final_bias)\n",
    "    return logits\n",
    "\n",
    "logits=multiplayer_perceptron(X,no_labels)\n",
    "learning_rate=0.01\n",
    "#we define the loss and optimiser for the network\n",
    "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y))\n",
    "optimiser=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op=optimiser.minimize(loss_op)\n",
    "#initialize the variables\n",
    "init=tf.global_variables_initializer()\n",
    "epochs=20\n",
    "batch_size=1000\n",
    "iteration=len(x_train)//batch_size\n",
    "                              \n",
    "#train model\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    average_cost=0\n",
    "    start,end=0\n",
    "    batch_size\n",
    "    for i in range(iteration):\n",
    "        batch_x, batch_y = x_train[start:end],y_train[start:end]\n",
    "        _, loss=session.run([train_op,loss_op],feed_dict={X:batch_x,Y:batch_y})\n",
    "        start += batch_size\n",
    "        end += batch_size\n",
    "        #average loss\n",
    "        average_cost += loss/iteration\n",
    "    print(\"Epoch==========={}\".format(epoch))\n",
    "\n",
    "#evaluate model\n",
    "prediction = tf.nn.softmax(logits)\n",
    "ground_truth = tf.equal(tf.argmax(prediction,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(ground_truth,\"float\"))\n",
    "print(\"Accuracy: {}\".format(accuracy.eval({X:test_images,Y:test_labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common regularization for deep learning\n",
    "\n",
    "Regularisation prevents overfitting in models\n",
    "Models are also susceptible to overfitting.\n",
    "Different methods have been developed to prevent overfitting.\n",
    "L1 & L2 regularization, dropout, data augmentation and early stopping and regularization methods.\n",
    "\n",
    "1.Dropout - this is a frequently used technique in DL where units are ignored (dropped out) in a neural network. A % of the neurons in each layer in the network are randomly selected and ignored such that they do not make any contribution in the forward and backward pass. \n",
    "This results in a much smaller network where the neurons left are required to handle the representations that would have been used for predictions by the missing neurons by learning more robust features. This process improves the generalization capabilities of the network and reduces overfitting on the training data. \n",
    "\n",
    "2. Early stopping - when a model is trained for a longer period such that the validation error starts to increase, overfitting is said to occur. In early stopping, while fitting the model on the training data and evaluating on the validation set, when the validation errors stops reducing or gets worse, the training process is terminated before the lowest training error is obtained to prevent overfitting.\n",
    "\n",
    "3. Data Augmentation - training the model on a larger dataset is another way to prevent overfitting. It involves increasing the size of training set by introducing minor changes like rotating, cropping, flipping, translating, blurring to generate synthetic data from the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation for training deep neural networks\n",
    "\n",
    "When we solve DL problems, a loss function is defined to minimize the loss using an optimisation algorithm like:\n",
    "1. Gradient descent\n",
    "2. Gradient descent with momentum\n",
    "3. Adagrad\n",
    "4. RMSProp\n",
    "5. Adam\n",
    "\n",
    "There are several optimisation algorithms but there are also some challenges such as:\n",
    "1.local minima\n",
    "2. saddle points\n",
    "3. vanishing gradients etc faced in DL optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Local minima\n",
    "\n",
    "- Neural networks aim to continue updating weights until the global minimum (the lowest point of the entire network) is attained.\n",
    "Local minima refer to the lowest points of localised portions of the graph.\n",
    "The value of a loss function is minimum at a point in the local region. \n",
    "It isi possible for the function to be stuck at a local minimum because it is best point in that locality which makes it difficult to reach the global minimum where the lowest loss can be achieved.\n",
    "\n",
    "Vanishing gradeints\n",
    "- This is a problem that happens when training a network using gradient descent methods\n",
    "it makes it difficult to update the weights in the earlier layers of the network and worsens as the number of layers increases. \n",
    "As we know, with gradient descent, the gradient controls how much learning happens in the network while training.\n",
    "While backpropagating in deep neural networks , the gradoents tend to get smaller and with small gradients, little or no learning is done that is why resutlnig poor performance of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
